{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Домашнее задание «Функции потерь и оптимизация» обновленное"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Этапы работы:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "irises = datasets.load_iris()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Смотрим, какие у нас есть ключи в датасете"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "keys = irises.keys()\n",
    "print(keys)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "смотрим, какие есть целевые названия ирисов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(irises.target_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "смотрим, что у нас в данных и что это за данные"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(irises.feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]]\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(irises.data[:15])\n",
    "print(len(irises.data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "смотрим, что у нас в таргетах"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(irises.target)\n",
    "print(len(irises.target))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Не вижу смысла специально удалять лишний класс в самом датасете (преобразовывать сам датасет, тратя на это усилия), потому что проще будет выбрать из датасета данные и целевые классы, сразу же раскидав их в параметры для обучения, что мы и сделаем заранее."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "X_origin = irises.data\n",
    "for index, item in enumerate(irises.target):\n",
    "    if item == 1 or item == 2:\n",
    "        X.append(X_origin[index])\n",
    "        Y.append(item - 1) # нормализуем\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Самостоятельно реализуйте логистическую регрессию, без использования метода LogisticRegression из библиотеки. Можете использовать библиотеки pandas, numpy, math для реализации. Оформите в виде функции. *Оформите в виде класса с методами.\n",
    "3. Реализуйте метод градиентного спуска. Обучите логистическую регрессию этим методом. Выберите и посчитайте метрику качества. Метрика должна быть одинакова для всех пунктов домашнего задания. Для упрощения сравнения выберите только одну метрику.\n",
    "4. Повторите п. 3 для метода скользящего среднего (Root Mean Square Propagation, RMSProp).\n",
    "5. Повторите п. 3 для ускоренного по Нестерову метода адаптивной оценки моментов (Nesterov–accelerated Adaptive Moment Estimation, Nadam)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class MyLogisticRegression():\n",
    "\n",
    "    # так как мне не нужно рисовать диаграммы на плоскости, ограничиваясь только двумя признаками,\n",
    "    # я использую все признаки из X = irises.data\n",
    "    def theta(self, theta, X):\n",
    "        return theta[0] + theta[1] * X[:, 0] + theta[2] * X[:, 1] + theta[3] * X[:, 2] + theta[4] * X[:, 3]\n",
    "\n",
    "    def sigmoid(self, theta):\n",
    "        return 1./(1 + np.exp(-theta))\n",
    "\n",
    "    def predict(self, theta, X):\n",
    "        return self.sigmoid(self.theta(theta, X))\n",
    "\n",
    "    def loss_function(self, Y, sigmoid):\n",
    "        return np.sum(np.square(sigmoid - Y)) / (2 * len(sigmoid))\n",
    "        # return - np.mean(np.log(sigmoid) * Y + np.log(1 - sigmoid) * (1 - Y))\n",
    "\n",
    "    def predict_grad(self, X, Y, epochs, rate, theta):\n",
    "        losses = []\n",
    "        for _ in range(epochs):\n",
    "            sigmoid = self.predict(theta, X)\n",
    "            loss = self.loss_function(Y, sigmoid)\n",
    "            losses.append(loss)\n",
    "            theta[0] = theta[0] - rate * np.sum(sigmoid - Y) / len(sigmoid)\n",
    "            theta[1] = theta[1] - rate * np.sum((sigmoid - Y) * X[:, 0])/len(sigmoid)\n",
    "            theta[2] = theta[2] - rate * np.sum((sigmoid - Y) * X[:, 1])/len(sigmoid)\n",
    "            theta[3] = theta[3] - rate * np.sum((sigmoid - Y) * X[:, 2])/len(sigmoid)\n",
    "            theta[4] = theta[4] - rate * np.sum((sigmoid - Y) * X[:, 3])/len(sigmoid)\n",
    "            # возвращаем итоговые коэффициенты theta, первое и последнее значение loss, чтобы видеть уменьшение функции потерь,\n",
    "            # а также для метрики качества используем подсчет ошибок предсказания\n",
    "        return [theta, losses[0], losses[len(losses) - 1], self.count_errors(X, Y, theta)]\n",
    "\n",
    "    # воспользуемся определениями 13 и 14 из источника https://habr.com/ru/post/318970/ для определения\n",
    "    # квадрата градиента и бегущего среднего, эпсилон и гамма - произвольно подбираемые коэффициенты\n",
    "    def predict_rmsprop(self, X, Y, epochs, rate, epsilon, gamma, theta):\n",
    "        # иницируем нулями массивы градиента и бегущего среднего\n",
    "        grad = np.zeros(5)\n",
    "        sq_grad = np.zeros(5)\n",
    "        losses = []\n",
    "        for _ in range(epochs):\n",
    "            sigmoid = self.predict(theta, X)\n",
    "            loss = self.loss_function(Y, sigmoid)\n",
    "            losses.append(loss)\n",
    "            grad[0] = np.sum(sigmoid - Y)/len(sigmoid)\n",
    "            grad[1] = np.sum((sigmoid - Y) * X[:, 0])/len(sigmoid)\n",
    "            grad[2] = np.sum((sigmoid - Y) * X[:, 1])/len(sigmoid)\n",
    "            grad[3] = np.sum((sigmoid - Y) * X[:, 2])/len(sigmoid)\n",
    "            grad[4] = np.sum((sigmoid - Y) * X[:, 3])/len(sigmoid)\n",
    "            sq_grad = gamma * sq_grad + (1 - gamma)  * grad ** 2\n",
    "            theta -= rate * grad / np.sqrt(sq_grad + epsilon)\n",
    "        return [theta, losses[0], losses[len(losses) - 1], self.count_errors(X, Y, theta)]\n",
    "\n",
    "    # воспользуемся определениями 3, 4 и 5 из источника https://habr.com/ru/post/318970/ для определения\n",
    "    # экспоненциального скользящего среднего, гамма - произвольно подбираемый коэффициент от 0 до 1, обычно близко к 0.9\n",
    "    def predict_nadam(self, X, Y, epochs, rate, gamma, theta):\n",
    "        # инициируем нулями массивы экспоненциального скользящего среднего - текущее и предыдущее\n",
    "        vt = np.zeros(5)\n",
    "        vt_prev = np.zeros(5)\n",
    "        losses = []\n",
    "        for _ in range(epochs):\n",
    "            sigmoid = self.predict(theta, X)\n",
    "            loss = self.loss_function(Y, sigmoid)\n",
    "            losses.append(loss)\n",
    "            sigmoid = self.predict(theta - gamma * vt_prev, X)\n",
    "            vt[0] = (gamma * vt_prev[0] + rate * np.sum(sigmoid - Y))/len(sigmoid)\n",
    "            vt[1] = (gamma * vt_prev[1] + rate * np.sum((sigmoid - Y) * X[:, 0]))/len(sigmoid)\n",
    "            vt[2] = (gamma * vt_prev[2] + rate * np.sum((sigmoid - Y) * X[:, 1]))/len(sigmoid)\n",
    "            vt[3] = (gamma * vt_prev[3] + rate * np.sum((sigmoid - Y) * X[:, 2]))/len(sigmoid)\n",
    "            vt[4] = (gamma * vt_prev[4] + rate * np.sum((sigmoid - Y) * X[:, 3]))/len(sigmoid)\n",
    "            theta -= vt\n",
    "            vt_prev = vt\n",
    "        return [theta, losses[0], losses[len(losses) - 1], self.count_errors(X, Y, theta)]\n",
    "\n",
    "    def count_errors(self, X, Y, theta):\n",
    "        count = 0\n",
    "        for index, item in enumerate(np.around(self.predict(theta, X))):\n",
    "            # print(int(item), Y[index].item())\n",
    "            if int(item) != Y[index].item():\n",
    "                count += 1\n",
    "        return count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1.49356576, -1.85876646, -0.83705399,  2.47340578,  2.08072563]), 0.2499957613795874, 0.02927782663823318, 3]\n",
      "0:00:02.617712\n"
     ]
    }
   ],
   "source": [
    "#theta = np.random.normal(size=(5,))\n",
    "#print(theta)\n",
    "#случайный выбор theta для тестирования\n",
    "theta = np.asarray([-0.37221469, -0.3897146,   1.11826103, -1.81180707, -1.2799002 ])\n",
    "rg = MyLogisticRegression()\n",
    "start_time = datetime.now()\n",
    "print(rg.predict_grad(X, Y, 50000, 0.001, theta))\n",
    "print(datetime.now() - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-4.12039006, -3.59019217, -3.55884558,  5.38330486,  6.20968826]), 0.2499957613795874, 0.013747702466034802, 3]\n",
      "0:00:02.814012\n"
     ]
    }
   ],
   "source": [
    "#не забываем реанимировать исходный массив theta, так как он уже изменен предыдущим методом по ссылке :)\n",
    "theta = [-0.37221469, -0.3897146,   1.11826103, -1.81180707, -1.2799002 ]\n",
    "start_time = datetime.now()\n",
    "print(rg.predict_rmsprop(X, Y, 50000, 0.01, 0.9999, 0.99999, theta))\n",
    "print(datetime.now() - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-4.13738611, -3.59664927, -3.56921045,  5.39443819,  6.22876313]), 0.2499957613795874, 0.013728142819197065, 3]\n",
      "0:00:03.191954\n"
     ]
    }
   ],
   "source": [
    "theta = [-0.37221469, -0.3897146,   1.11826103, -1.81180707, -1.2799002 ]\n",
    "start_time = datetime.now()\n",
    "print(rg.predict_nadam(X, Y, 50000, 0.01, 0.9, theta))\n",
    "print(datetime.now() - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Сравните значение метрик для реализованных методов оптимизации. Можно оформить в виде таблицы вида |метод|метрика|время работы| (время работы опционально). Напишите вывод."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В целом сравнение показывает, что время работы методов при похожих начальных условиях отличаются незначительно, главное - подобрать коэффициенты для скользящего среднего и Нестерова, кол-во ошибок также одинаковое и незначительное (выбрано в качестве метрики качества)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}